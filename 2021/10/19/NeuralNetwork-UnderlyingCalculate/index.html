<!DOCTYPE html>


<html lang="en">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="å¥‡ç‚¹åšå®¢â€”â€”åšæ–‡å†…å®¹æ¶µç›–ï¼šè‡ªåŠ¨åŒ–æ§åˆ¶ã€ç¡¬ä»¶è®¾è®¡ã€åµŒå…¥å¼è½¯ä»¶ã€é‡‘èã€ä¸ªäººè®¤çŸ¥" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>æ·±åˆ»ç†è§£ç¥ç»ç½‘ç»œè®¡ç®—åŸç† |  Singularity-blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/S-favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-NeuralNetwork-UnderlyingCalculate"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  æ·±åˆ»ç†è§£ç¥ç»ç½‘ç»œè®¡ç®—åŸç†
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/10/19/NeuralNetwork-UnderlyingCalculate/" class="article-date">
  <time datetime="2021-10-19T12:44:47.000Z" itemprop="datePublished">2021-10-19</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">äººå·¥æ™ºèƒ½</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">5.2k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading timeâ‰ˆ</span>
            <span class="post-count">25 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <blockquote>
<p>ç¬”è€…åˆå…¥<strong>æ·±åº¦å­¦ä¹ </strong>å…ˆæ˜¯ä½¿ç”¨TensorFlowåè½¬PyTorchï¼Œä½†éƒ½æ˜¯åœ¨æ¡†æ¶ä¸Šè¿›è¡Œå¼€å‘ï¼Œåªèƒ½ç†è§£å„ç§ç½‘ç»œç»“æ„çš„â€œå¤´å£â€åŸç†ã€‚åœ¨å­¦ä¹ çš„ä¸­åæœŸæˆ–è€…æ˜¯è¦åšè½åœ°çš„æ—¶å€™ï¼Œå°±ä¼šå›°æ‰°ä¸€ä¸ªéå¸¸å¸¸è§çš„é—®é¢˜â€”â€”æˆ‘ä»¬çš„ç½‘ç»œåˆ°åº•éœ€è¦å¤šå°‘çš„è®¡ç®—èµ„æºï¼Ÿæˆ‘ä»¬æš‚ä¸”å°†è®¡ç®—èµ„æºåœ¨ä¸¤æ–¹é¢è€ƒè™‘ï¼šæ˜¾å­˜å’Œæµ®ç‚¹è®¡ç®—æ¬¡æ•°ã€‚è¿™å°±éœ€è¦å¯¹ç½‘ç»œè®¡ç®—è¿‡ç¨‹çš„åº•å±‚æœ‰é€å½»ç›´æ¥çš„è®¤è¯†ï¼Œä¹Ÿå°±æ˜¯æœ¬æ–‡çš„é‡ç‚¹</p>
<blockquote>
<p>å¾ˆå¤šå‰å®³çš„å¤§ä½¬å¯ä»¥æ ¹æ®ç»éªŒã€ç›´è§‰ç›´æ¥åˆ¤æ–­å“ªäº›ç½‘ç»œå¯ä»¥åœ¨åµŒå…¥å¼å¹³å°ä¸Šè·‘ï¼Œä½†æ˜¯ç¬”è€…è¿˜æ˜¯åçˆ±å°†è¿‡ç¨‹é‡åŒ–</p>
</blockquote>
</blockquote>
<h2 id="å…¨è¿æ¥ç½‘ç»œ"><a href="#å…¨è¿æ¥ç½‘ç»œ" class="headerlink" title="å…¨è¿æ¥ç½‘ç»œ"></a>å…¨è¿æ¥ç½‘ç»œ</h2><p><img src="http://imgjry.fangyikuan.xyz/20211019/20211019-NNC-1.png" alt="æ¢¯åº¦ä¸‹é™"></p>
<p>ä¸ºäº†æ–¹ä¾¿è®¨è®ºï¼Œæˆ‘ä»¬é€‰å–å•éšè—å±‚çš„å…¨è¿æ¥ç½‘ç»œè¿›è¡Œè®¨è®ºã€‚é¦–å…ˆï¼Œå£°æ˜è¯¥ç½‘ç»œçš„è¾“å…¥ä¸ºï¼š</p>
<p>$$<br>x_0 &#x3D; \begin{bmatrix}<br>    x_0^{(1)} \\<br>    x_0^{(2)} \\<br>    \vdots \\<br>    x_0^{(m_0)}<br>\end{bmatrix} \sim [m_0,1]<br>$$</p>
<p>æœ¬æ–‡ä¸­æ‰€æœ‰å…¬å¼ä¸­<code>~</code>åçš„ä¸ºçŸ©é˜µã€å‘é‡çš„ç»´åº¦ã€‚ç„¶è€Œï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¸€æ¬¡ä½¿ç”¨å‡ ä¸ªæ ·æœ¬ä¸€èµ·è®­ç»ƒç½‘ç»œï¼ˆmini-batchï¼‰ï¼Œé‚£ä¹ˆä¸€æ¬¡è¾“å…¥ç½‘ç»œçš„æ•°æ®å°±æ˜¯ï¼š</p>
<p>$$<br>X_0 &#x3D; \begin{bmatrix}<br>    x_{0,1} ,<br>    x_{0,2} ,<br>    \cdots ,<br>    x_{0,N}<br>\end{bmatrix} \sim [m_0,N]<br>$$</p>
<span id="more"></span>

<p>ç°åœ¨è§„å®šä¸€å±‚å…¨è¿æ¥çš„è®¡ç®—å‚æ•°ï¼š</p>
<p>$$<br>æƒé‡W_1 &#x3D; \begin{bmatrix}<br>    w_1^{(0,0)},w_1^{(0,1)},\cdots,w_1^{(0,m_0)} \\<br>    \vdots \\<br>    w_{1}^{(m_1,0)},w_1^{(m_1,1)},\cdots,w_1^{(m_1,m_0)}<br>\end{bmatrix} \sim [m_1,m_0]<br>\\<br>åç½®B_1 &#x3D; \begin{bmatrix}<br>    b_1^0, \\<br>    b_1^2, \\<br>    \vdots \\<br>    b_1^{m_1}<br>\end{bmatrix} \sim [m_1,1]<br>$$</p>
<p>åŒç†å…¶ä»–å±‚çš„å‚æ•°ç»´åº¦ä¹Ÿæ˜¯ï¼š</p>
<p>$$<br>W_l \sim [m_l,m_{l-1}],B_l \sim [m_l,1]<br>$$</p>
<p>åˆ™ä¸Šå›¾ä¸­çš„å•å±‚å…¨è¿æ¥ç½‘ç»œï¼Œæˆ‘ä»¬å¯ä»¥å°†æ­£å‘ä¼ æ’­è¿‡ç¨‹è¡¨ç¤ºä»¥çº¿æ€§è®¡ç®—å’Œéçº¿æ€§æ¿€æ´»ä¸¤éƒ¨åˆ†æ‹†åˆ†ä¸ºï¼š</p>
<p>$$<br>Z_1 &#x3D; W_1\cdot X_0 + B_1<br>\\ \sim [m_1,N] &#x3D; [m_1,m_0]\cdot [m_0,N] + [m_1,1]<br>\\<br>Y_1 &#x3D; f_1(Z_1) \sim [m_1,N]<br>\\<br>X_1 &#x3D; Y_1<br>\\<br>Z_2 &#x3D; W_2\cdot X_1 + B_2 &#x3D; \begin{bmatrix}<br>    z_{2,1} ,<br>    z_{2,2} ,<br>    \cdots ,<br>    z_{2,N}<br>\end{bmatrix}<br>\\ \sim [m_2,N] &#x3D; [m_2,m_1]\cdot [m_1,N] + [m_2,1]<br>\\<br>Y_2 &#x3D; f_2(Z_2) \sim [m_2,N]<br>\\<br>\hat{Y} &#x3D;Y_2 &#x3D; \begin{bmatrix}<br>    \hat{y_0} ,<br>    \hat{y_1} ,<br>    \cdots ,<br>    \hat{y_N}<br>\end{bmatrix},<br>\hat{y_i} &#x3D; \begin{bmatrix}<br>    \hat{y_i}^{(0)} \\<br>    \hat{y_i}^{(1)} \\<br>    \vdots \\<br>    \hat{y_i}^{(m_2)}<br>\end{bmatrix} \sim [m_2,1]<br>$$</p>
<blockquote>
<p>ä¸Šé¢åœ¨çº¿æ€§å±‚è®¡ç®—çš„æ—¶å€™ï¼Œè¯»è€…ä¼šå‘ç°åšåŠ åˆ†çš„æ—¶å€™ï¼Œç»´åº¦ä¸åŒ¹é…ã€‚ä¸ç”¨æ‹…å¿ƒï¼Œåœ¨æˆ‘ä»¬ä»£ç ä¸­è®¡ç®—çš„æ—¶å€™ï¼ŒçŸ©é˜µåº“ä¼šè‡ªåŠ¨å¸®æˆ‘ä»¬æ‰©å±•ï¼ˆå‚è§Numpyæˆ–è€…TensorFlowçš„<strong>å¹¿æ’­</strong>æ¦‚å¿µï¼‰</p>
</blockquote>
<p>é‚£ä¹ˆï¼Œç°åœ¨æˆ‘ä»¬å¯¹è¯¥ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œåœ¨æ­£å‘ä¼ æ’­åéœ€è¦ä½œåå‘ä¼ æ’­æ¥è®¡ç®—æ¢¯åº¦ã€‚é¦–å…ˆï¼Œè¦å®šä¹‰ä¸€ä¸‹ç½‘ç»œçš„æŸå¤±(Loss)å‡½æ•°ï¼š</p>
<p>$$<br>L(W,B) &#x3D; \frac{1}{N} \sum^N_{i&#x3D;1} loss(\hat{y_i},y_i)<br>$$</p>
<p>æˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯æ ¹æ®æ¢¯åº¦ä¸æ–­æ›´æ–°ç½‘ç»œå‚æ•°ï¼Œä½¿å¾—è¯¥å‡½æ•°çš„ç»“æœæœ€å°ã€‚åˆ™å¯¹å„å¯è®­ç»ƒå‚æ•°çš„åå¯¼è®¡ç®—ï¼š</p>
<p>$$<br>\frac{\partial L(W,B)}{\partial Z_2} &#x3D; \frac{\partial L(W,B)}{\partial Y_2} \cdot \frac{\partial Y_2}{\partial Z_2}<br>$$</p>
<p>$$<br>&#x3D; \frac{1}{N} *<br>\begin{bmatrix}<br>    \frac{\partial loss(\hat{y_1},y_1)}{\partial \hat{y_1}}, \cdots , \frac{\partial loss(\hat{y_N},y_N)}{\partial \hat{y_N}}<br>\end{bmatrix} *<br>\begin{bmatrix}<br>    \frac{\partial \hat{y_1}}{\partial z_{2,1}}, \cdots , \frac{\partial \hat{y_N}}{\partial z_{2,N}}<br>\end{bmatrix}<br>$$</p>
<p>$$<br>&#x3D; \frac{1}{N} *<br>\begin{bmatrix}<br>    \frac{\partial loss(\hat{y_1},y_1)}{\partial \hat{y_1}} * \frac{\partial \hat{y_1}}{\partial z_{2,1}}<br>    , \cdots,<br>    \frac{\partial loss(\hat{y_N},y_N)}{\partial \hat{y_N}} * \frac{\partial \hat{y_N}}{\partial z_{2,N}}<br>\end{bmatrix} \\ \sim  [m_2,N] * [m_2,N] &#x3D; [m_2,N]<br>$$</p>
<blockquote>
<p>æ³¨æ„ï¼šä¸Šå¼ä¸­ä¸¤æ¬¡åå¯¼çš„ç»“æœæ˜¯é€šè¿‡<strong>æ•°ä¹˜</strong><code>*</code>ä¼ é€’çš„ï¼Œè€Œä¸æ˜¯çŸ©é˜µä¹˜æ³•ã€‚æ¶ˆåŒ–è¿™ä¸ªæ¯”è¾ƒå›°éš¾ï¼Œå› ä¸ºè§’æ ‡å¤ªå¤šäº†ï¼Œç¬”è€…ç¬¬ä¸€æ¬¡å°è¯•ç†è§£ä¹Ÿå¤±è´¥äº†ï¼Œåé¢çœ‹å®Œå®ä¾‹é¡¹ç›®ï¼ˆå‡½æ•°éƒ½æ˜¯å…·ä½“å¯¹è±¡ï¼‰çš„åå‘ä¼ æ’­å¯èƒ½ä¼šæç„¶å¤§æ‚Ÿ</p>
</blockquote>
<p>ä»ä¸Šé¢çš„å¼å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼Œä½¿ç”¨mini-Batchçš„æ–¹å¼ä¸€æ‰¹æ‰¹æ ·æœ¬è¿›å»ï¼Œæœ€ååå‘ä¼ æ’­çš„æ—¶å€™ï¼Œå…¶å®å¯ä»¥åˆ†æˆæ¯ä¸ªå•ç‹¬æ ·æœ¬æ±‚å¯¼ï¼Œæœ€åä½œå¹³å‡æ±‚å’Œã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥æŠŠå…¶ä»–å‚æ•°çš„åå¯¼éƒ½å…ˆä»¥å•ä¸ªæ ·æœ¬çš„å½¢å¼æ±‚è§£ï¼Œæœ€åä»¥Batchè¿›è¡Œå½’çº³ï¼š</p>
<p>$$<br>\frac{\partial L}{\partial W_2} &#x3D; \frac{\partial L}{\partial Z_2} \cdot \frac{\partial Z_{2}}{\partial W_2} &#x3D;  \frac{\partial L}{\partial Z_2} \cdot X_1^T<br>\\ &#x3D; \frac{1}{N} \begin{bmatrix}<br>    [\frac{\partial loss(\hat{y_1},y_1)}{\partial \hat{y_1}} * \frac{\partial \hat{y_1}}{\partial z_{2,1}}]\cdot x_{1,1}^T + \cdots + [\frac{\partial loss(\hat{y_N},y_N)}{\partial \hat{y_N}} * \frac{\partial \hat{y_N}}{\partial z_{2,N}}]\cdot x_{1,N}^T<br>\end{bmatrix}<br>\\ \sim [m_2,m_1] &#x3D; [m_2,N] \cdot [m_1,N] ^T<br>$$</p>
<blockquote>
<p>è¿™ä¸ªåœ°æ–¹ä¹Ÿè®¸ä¼šæœ‰äººè§‰å¾—å¾ˆæ€ªï¼Œä¸ºä»€ä¹ˆåé¢çš„xå‘é‡è¦ä½œè½¬ç½®ï¼Ÿè¿™é‡Œç¬”è€…æ˜¯ä»çŸ©é˜µç›¸ä¹˜çš„è§„åˆ™å»ç†è§£ã€‚</p>
</blockquote>
<p>$$<br>\frac{\partial L}{\partial B_2} &#x3D;<br>\frac{\partial L}{\partial Z_{2}} \cdot \frac{\partial Z_{2}}{\partial B_2} &#x3D;\frac{\partial L}{\partial Z_{2}} \cdot 1<br>\\ &#x3D; \frac{1}{N} \begin{bmatrix}<br>    [\frac{\partial loss(\hat{y_1},y_1)}{\partial \hat{y_1}} * \frac{\partial \hat{y_1}}{\partial z_{2,1}}] + \cdots + [\frac{\partial loss(\hat{y_N},y_N)}{\partial \hat{y_N}} * \frac{\partial \hat{y_N}}{\partial z_{2,N}}]<br>\end{bmatrix}<br>\\ \sim [m_2,1]<br>$$</p>
<p>è¿™æ ·å°±å®Œæˆäº†æœ€åä¸€å±‚çš„åå¯¼è®¡ç®—ï¼Œä¸€æ ·çš„æˆ‘ä»¬ç»§ç»­æ±‚å‰ä¸€å±‚åå¯¼ã€‚é¦–å…ˆæ˜¯å‰ä¸€å±‚æ¿€æ´»è¾“å‡ºï¼š</p>
<p>$$<br>\frac{\partial L}{\partial Y_1} &#x3D; \frac{\partial L}{\partial Z_{2}} \cdot \frac{\partial Z_{2}}{\partial Y_1} &#x3D; [\frac{\partial L}{\partial Z_{2}} ^T \cdot W_2 ]^T<br>\\  &#x3D;<br>\\ \sim [m_1,N] &#x3D; \begin{bmatrix}<br>    [m_2,N]^T \cdot [m2,m_1]<br>\end{bmatrix} ^ T<br>$$</p>
<p>ä»¥åŠçº¿æ€§è¾“å‡ºåå¯¼ï¼š</p>
<p>$$<br>\frac{\partial L}{\partial Z_1} &#x3D; \frac{\partial L}{\partial Y_1}\cdot \frac{\partial Y_1}{\partial Z_1} &#x3D; \frac{\partial L}{\partial Y_1} * f_1â€™(Z_1)<br>\\ \sim [m_1,N] &#x3D; [m_1,N] * [m_1,N]<br>$$</p>
<p>åˆ™å¯ä»¥å¾—åˆ°å¯è®­ç»ƒå‚æ•°çš„åå¯¼ä¸ºï¼š</p>
<p>$$<br>\frac{\partial L}{\partial W_1} &#x3D; \frac{\partial L}{\partial Z_1}\cdot \frac{\partial Z_1}{\partial W_1} &#x3D; \frac{\partial L}{\partial Z_1}\cdot X_0^T<br>\\ \sim  [m_1,m_0] &#x3D; [m_1,N] \cdot [m_0,N] ^ T<br>$$</p>
<p>$$<br>\frac{\partial L}{\partial B_1} &#x3D; \frac{\partial L}{\partial Z_1}\cdot \frac{\partial Z_1}{\partial B_1} &#x3D;  \frac{\partial L}{\partial Z_1}\cdot 1<br>\\ \sim [m_1,1]<br>$$</p>
<h2 id="MNISTåˆ†ç±»å®æˆ˜"><a href="#MNISTåˆ†ç±»å®æˆ˜" class="headerlink" title="MNISTåˆ†ç±»å®æˆ˜"></a>MNISTåˆ†ç±»å®æˆ˜</h2><p>æ ¹æ®ä¸Šé¢çš„æ¨å¯¼ï¼Œæˆ‘ä»¬å¯ä»¥æŠ½è±¡åœ°äº†è§£ï¼ˆå…¨è¿æ¥ï¼‰ç½‘ç»œçš„åŸç†ä¸è®¡ç®—è¿‡ç¨‹ï¼Œä½†å…¨éƒ½æ˜¯å…¬å¼ä»¥åŠæ¦‚å¿µï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®é™…æ“ä½œä¸€ä¸‹ç”¨numpyç§‘å­¦è®¡ç®—åº“æ­å»ºå•å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œè¯†åˆ«MNISTæ•°æ®é›†ä¸­çš„æ•°å­—ã€‚</p>
<h3 id="è®¡ç®—è¿‡ç¨‹åˆ†æ"><a href="#è®¡ç®—è¿‡ç¨‹åˆ†æ" class="headerlink" title="è®¡ç®—è¿‡ç¨‹åˆ†æ"></a>è®¡ç®—è¿‡ç¨‹åˆ†æ</h3><p>é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆæŠŠä¸Šé¢åˆ†æçš„ç½‘ç»œå…·ä½“å‚æ•°åŒ–ï¼Œç½‘ç»œçš„ç»“æ„å®šä¹‰ï¼š</p>
<p>$$<br>è¾“å…¥å±‚m_0 &#x3D; 28*28<br>\\<br>éšè—ï¼ˆå•ï¼‰å±‚m_1 &#x3D; 128<br>\\<br>è¾“å‡ºå±‚m_2 &#x3D; 10<br>$$</p>
<p>ä»¥åŠç½‘ç»œçš„æ¿€æ´»å‡½æ•°å’ŒæŸå¤±å‡½æ•°ï¼š</p>
<p>$$<br>f_1(z) &#x3D; ReLU(z) &#x3D;<br>\begin{cases}<br>    z , z&gt;0<br>    \\ 0, z \le 0<br>\end{cases}<br>$$</p>
<p>$$<br>f_2(Z_2)&#x3D; softmax(Z_2) &#x3D; \frac{e^{Z_2}}{ \sum^{m_2}_{k&#x3D;1} e^{ Z_2^{(k)} } }<br>$$</p>
<p>$$<br>loss(\hat{y_i},y_i) &#x3D; -\sum^{m_2}_{k&#x3D;1} y_i^{(k)} \ln(\hat{y}_i^{(k)})<br>$$</p>
<blockquote>
<p>æ³¨æ„ä¸ä¸Šé¢æˆ‘ä»¬æ¨å¯¼å…¨è¿æ¥å…¬å¼ä¸­çš„ç¬¦å·è¿›è¡Œé€»è¾‘é—­ç¯ã€‚ç¬¬ä¸€ä¸ªæ¿€æ´»å‡½æ•°ä¸­çš„å˜é‡æ˜¯å°å†™<code>z</code>ï¼Œè¡¨ç¤ºå®æ•°ï¼›ç¬¬äºŒä¸ªæ¿€æ´»å‡½æ•°ï¼Œå·²ç»ä¸ä¸Šé¢æˆ‘ä»¬æ¨å¯¼çš„è¾“å‡ºå±‚ç¬¦å·åŒæ­¥ï¼Œè®¤çœŸè§‚å¯Ÿï¼Œç¬”è€…åœ¨å³ä¸Šè§’åŠ çš„è§’æ ‡åœ¨ä¸Šé¢æ¨å¯¼ä¸­æ˜¯è¡¨ç¤ºç¬¬å‡ è¡Œï¼Œå› ä¸ºè¿™é‡Œé¢çš„é™¤æ³•å…¶å®æ˜¯ä¸€ä¸ªï¼ˆBatchSizeå®½çš„ï¼‰çŸ©é˜µé™¤æ³•ï¼</p>
</blockquote>
<h3 id="æœ€å›°éš¾çš„ç¬¬ä¸€æ­¥ï¼Œè¾“å‡ºå±‚åå¯¼"><a href="#æœ€å›°éš¾çš„ç¬¬ä¸€æ­¥ï¼Œè¾“å‡ºå±‚åå¯¼" class="headerlink" title="æœ€å›°éš¾çš„ç¬¬ä¸€æ­¥ï¼Œè¾“å‡ºå±‚åå¯¼"></a>æœ€å›°éš¾çš„ç¬¬ä¸€æ­¥ï¼Œè¾“å‡ºå±‚åå¯¼</h3><p>ç°åœ¨æˆ‘ä»¬æ¨å¯¼ä¸€ä¸‹æŸå¤±å‡½æ•°ï¼ˆäº¤å‰ç†µï¼‰çš„å¯¼æ•°ï¼š</p>
<p>$$<br>\frac{\partial loss(\hat{y_i},y_i)}{\partial \hat{y}_i^{(j)}} &#x3D; y_i^{(j)} \frac{1}{\hat{y}_i^{(j)}}<br>$$</p>
<p>ä»¥åŠè¾“å‡ºå±‚softmaxæ¿€æ´»å‡½æ•°çš„å¯¼æ•°ï¼Œä½†æ˜¯ä¸ºäº†æ–¹ä¾¿ç†è§£ï¼Œæˆ‘ä»¬å…ˆæ¨å¯¼å•ä¸ªåˆ—å‘é‡ï¼ˆä¸€ä¸ªBatchSizeå®½åº¦ï¼‰çš„æƒ…å†µï¼š</p>
<p>$$<br>f_2( Z_{2,i} ) &#x3D; softmax( Z_{2,i} )<br>&#x3D; \frac{ e^{ Z_{2,i} } }{ \sum^{ m_2 } _ { k&#x3D;1 } e^{ Z _ { 2,i }^{ (k) } } } &#x3D;<br>\begin{bmatrix}<br>    \frac{e^{Z^{(1)} _ {2,i}}}{\sum^{m_2} _ {k&#x3D;1} e^{Z_{2,i}^{(k)}}}<br>    \\<br>    \vdots<br>    \\<br>    \frac{e^{Z^{(m_2)} _ {2,i}}}{\sum^{m_2} _ {k&#x3D;1} e^{Z_{2,i}^{(k)}}}<br>\end{bmatrix}<br>$$</p>
<p>$$<br>fâ€™ _ 2 &#x3D; \frac{\partial}{\partial Z^{(j)} _ {2,i} } \frac{e^{Z^{(k)} _ {2,i}}}{\sum^{m_2} _ {k&#x3D;1} e^{Z _ {2,i}^{(k)}}} &#x3D;<br>\begin{cases}<br>    \frac{e^{Z_{2,i}^{(j)}} \sum_{k&#x3D;1}^{m_2} e^{Z_{2,i}^{(k)}} - e^{Z_{2,i}^{(j)}}e^{Z_{2,i}^{(j)}}}{ [\sum_{k&#x3D;1}^{m_2} e^{Z_{2,i}^{(k)}}]^2 } &amp;, j&#x3D;k<br>    \\<br>    \frac{- e^{Z_{2,i}^{(j)}}e^{Z_{2,i}^{(k)}}}{ [\sum_{k&#x3D;1}^{m_2} e^{Z_{2,i}^{(k)}}]^2 } &amp;, j \ne k<br>\end{cases} \\&#x3D;<br>\begin{cases}<br>    \frac{e^{Z^{(j)} _ {2,i}}}{ \sum^{m_2}_ {k&#x3D;1} e^{Z_{2,i}^{(k)}} } [1- \frac{e^{Z^{(j)}_ {2,i}}}{ \sum^{m_2}_ {k&#x3D;1} e^{Z_ {2,i}^{(k)}} }] &#x3D; y_ {2,i}^{(j)}[1-y_ {2,i}^{(j)}] &amp;, j&#x3D;k<br>    \\<br>    -\frac{e^{Z^{(j)}_ {2,i}}}{ \sum^{m_2}_ {k&#x3D;1} e^{Z_ {2,i}^{(k)}} } \frac{e^{Z^{(k)}_ {2,i}}}{ \sum^{m_2}_ {k&#x3D;1} e^{Z_ {2,i}^{(k)}} } &#x3D; -y_{2,i}^{(j)}y_{2,i}^{(k)} &amp;, j \ne k<br>\end{cases} \\ &#x3D;<br>\begin{cases}<br>    \hat{y}_i^{(j)}[1-\hat{y}_i^{(j)}] &amp;, j&#x3D;k<br>    \\<br>    -\hat{y}_i^{(j)}\hat{y}_i^{(k)} &amp;, j \ne k<br>\end{cases}<br>$$</p>
<blockquote>
<p>Help Noticeï¼šè§’æ ‡<code>i</code>ä¸ºä¸€æ‰¹æ ·æœ¬ä¸­çš„æŸä¸ªæ ·æœ¬</p>
</blockquote>
<p>æŠŠä¸Šé¢ä¸¤ä¸ªåå¯¼åˆä½“ï¼Œå°±å¾—åˆ°äº†ï¼š</p>
<p>$$<br>\frac{\partial loss(\hat{y_i},y_i)}{\partial Z^{(j)} _ {2,i}}<br>&#x3D; -\frac{\partial}{\partial Z^{(j)} _ {2,i}} \sum^{m_2} _ {k&#x3D;1} y_i^{(k)} \ln(\hat{y}_i^{(k)})<br>&#x3D; -\sum^{m_2} _ {k&#x3D;1} y_i^{(k)} \frac{\partial}{\partial Z^{(j)} _ {2,i}} \ln(\hat{y}_i^{(k)})<br>\\<br>&#x3D; -\sum^{m_2} _ {k&#x3D;1} y_i^{(k)} \frac{\partial \ln(\hat{y} _ i^{(k)})}{\partial \hat{y} _ i^{(k)}} \frac{\partial \hat{y} _ i^{(k)}}{\partial Z^{(j)} _ {2,i}}<br>&#x3D; -\sum^{m_2} _ {k&#x3D;1} y_i^{(k)} \frac{1}{\hat{y} _ i^{(k)}} \frac{\partial \hat{y} _ i^{(k)}}{\partial Z^{(j)} _ {2,i}}<br>\\<br>&#x3D; -y_i^{(j)} \frac{1}{\hat{y}_i^{(j)}} \hat{y}_i^{(j)}[1-\hat{y}_i^{(j)}] + \sum^{m_2} _ {k\ne j} y_i^{(k)} \frac{1}{\hat{y}_i^{(k)}} \hat{y}_i^{(j)}\hat{y}_i^{(k)}<br>\\<br>&#x3D; -y_i^{(j)} [1-\hat{y}_i^{(j)}] + \sum^{m_2} _ {k\ne j} y_i^{(k)} \hat{y}_i^{(j)} &#x3D; -y_i^{(j)} + \sum^{m_2} _ {k&#x3D;1} y_i^{(k)} \hat{y}_i^{(j)}<br>$$</p>
<p>è¿™æ—¶å€™ï¼Œæˆ‘ä»¬æƒŠå–œåœ°å‘ç°ï¼åˆ†ç±»äº‹ä»¶çš„æ¦‚ç‡æ€»å’Œä¸€å®šæ˜¯<code>1</code>å‘€ï¼</p>
<p>$$<br>\because \sum_k y_i^{(k)} &#x3D; 1<br>\\ \therefore<br>\frac{\partial loss(\hat{y_i},y_i)}{\partial Z^{(j)}_{2,i}} &#x3D; \hat{y}_i^{(j)} - y_i^{(j)}<br>$$</p>
<p>é‚£ä¹ˆï¼Œæˆ‘ä»¬æŠŠä¸Šé¢è¿™ä¸ªå¼å­ï¼Œå½’çº³åˆ°ä¸€ä¸ªæ ·æœ¬çš„ç»´åº¦å»ï¼š</p>
<p>$$<br>\frac{\partial loss(\hat{y_i},y_i)}{\partial Z_{2,i}}  &#x3D; \hat{y}_i - y_i<br>$$</p>
<p>è¿‡ç¨‹å¤šä¹ˆçš„ç—›è‹¦ï¼ç»“æœå¤šä¹ˆçš„ç¾å¦™ï¼ğŸ‰ğŸŠâœ¨ğŸˆ</p>
<p>$$<br>\frac{\partial L(W,B)}{\partial Z_2} &#x3D; \frac{1}{N}(\hat{Y} - Y) \sim [m_2,N]<br>$$</p>
<h4 id="å¯è®­ç»ƒå‚æ•°åå¯¼"><a href="#å¯è®­ç»ƒå‚æ•°åå¯¼" class="headerlink" title="å¯è®­ç»ƒå‚æ•°åå¯¼"></a>å¯è®­ç»ƒå‚æ•°åå¯¼</h4><p>æœ€åä¸€å±‚çš„æƒé‡å’Œåç½®ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨ä¹‹å‰æ¨å¯¼çš„ç»“æœå°±å¥½ï¼š</p>
<p>$$<br>\frac{\partial L}{\partial W_2} &#x3D; \frac{\partial L}{\partial Z_2} \cdot X_1^T<br>\\<br>\frac{\partial L}{\partial B_2} &#x3D;<br>\frac{\partial L}{\partial Z_{2}} \cdot \frac{\partial Z_{2}}{\partial B_2} &#x3D;\frac{\partial L}{\partial Z_{2}} \cdot 1<br>$$</p>
<p>éšè—å±‚ï¼Œæˆ‘ä»¬é€‰ç”¨çš„ReLUæ¿€æ´»å‡½æ•°çš„å¯¼æ•°ä¸ºï¼š</p>
<p>$$<br>fâ€™_1(z) &#x3D; ReLUâ€™(z) &#x3D; \begin{cases}<br>    1 , z&gt;0<br>    \\ 0, z \le 0<br>\end{cases}<br>$$</p>
<p>é‚£ä¹ˆéšè—çš„è¾“å‡ºåå¯¼ä¸ºï¼š</p>
<p>$$<br>\frac{\partial L}{\partial Y_1} &#x3D; [\frac{\partial L}{\partial Z_{2}} ^T \cdot W_2 ]^T<br>\\<br>\frac{\partial L}{\partial Z_1} &#x3D; \frac{\partial L}{\partial Y_1} * f_1â€™(Z_1)<br>$$</p>
<blockquote>
<p>è¿™ä¸ªåœ°æ–¹å¯¼æ•°å±•å¼€å†™å¤ªç¹çäº†ï¼Œåœ¨ä¸‹é¢ä»£ç å®ç°ä¼šæ›´ç®€å•ç›´è§‚</p>
</blockquote>
<p>æ‰€ä»¥ï¼Œéšè—å±‚çš„å¯¼æ•°ä¸ºï¼š</p>
<p>$$<br>\frac{\partial L}{\partial W_1} &#x3D; \frac{\partial L}{\partial Z_1}\cdot X_0^T<br>\\<br>\frac{\partial L}{\partial B_1} &#x3D; \frac{\partial L}{\partial Z_1} \cdot 1<br>$$</p>
<h3 id="å…¨è¿æ¥ç½‘ç»œå®ç°"><a href="#å…¨è¿æ¥ç½‘ç»œå®ç°" class="headerlink" title="å…¨è¿æ¥ç½‘ç»œå®ç°"></a>å…¨è¿æ¥ç½‘ç»œå®ç°</h3><p>æ ¹æ®ä¸Šé¢çš„åˆ†æï¼Œç¬”è€…å°†å•å±‚å…¨è¿æ¥ç½‘ç»œå®ç°ä¸ºä¸€ä¸ªç±»ï¼š</p>
<blockquote>
<p>è¿™ä¸ªå°è£…åšçš„è¿˜æ˜¯æ¯”è¾ƒèœçš„ï¼Œåªæ˜¯ä¸ºäº†æ„Ÿå—è®¡ç®—è¿‡ç¨‹è€Œä¸æ˜¯é•¿è¿œå¼€å‘</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FC</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,inputS:<span class="built_in">int</span>=<span class="number">64</span>,hidWidth:<span class="built_in">int</span>=<span class="number">64</span>,outputS:<span class="built_in">int</span>=<span class="number">10</span>,active:<span class="built_in">str</span>=<span class="string">&quot;relu&quot;</span>,preCacheSize:<span class="built_in">int</span> = <span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        åªæ”¯æŒå•éšè—å±‚çš„å…¨è¿æ¥ç½‘ç»œ</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        inputS : int, optional</span></span><br><span class="line"><span class="string">            è¾“å…¥ç»´åº¦. The default is 64.</span></span><br><span class="line"><span class="string">        hidWidth : int, optional</span></span><br><span class="line"><span class="string">            éšè—å®½åº¦. The default is 64.</span></span><br><span class="line"><span class="string">        outputS : int, optional</span></span><br><span class="line"><span class="string">            è¾“å‡ºç»´åº¦. The default is 10.</span></span><br><span class="line"><span class="string">        active : string, optional</span></span><br><span class="line"><span class="string">            æ¿€æ´»å‡½æ•°. The default is &quot;ReLU&quot;.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.inputCache = np.zeros(shape=inputS)</span><br><span class="line">        </span><br><span class="line">        self.param = [  <span class="comment"># å‚æ•°listï¼Œæ¯ä¸ªå°listä»£è¡¨ä¸€ä¸ªå±‚çš„æƒé‡å’Œåç½®</span></span><br><span class="line">                        [], <span class="comment"># ç©ºåˆ—è¡¨ï¼Œç”¨æ¥ç»Ÿä¸€åŒ–idåºå·</span></span><br><span class="line">                        <span class="comment">#&#x27;&#x27;&#x27;ç¬¬ä¸€å±‚&#x27;&#x27;&#x27;</span></span><br><span class="line">                        [ np.random.normal(size=(hidWidth,inputS)),     <span class="comment">#æƒé‡</span></span><br><span class="line">                          np.zeros(shape=(hidWidth,<span class="number">1</span>))], <span class="comment">#åç½®</span></span><br><span class="line">                        <span class="comment">#&#x27;&#x27;&#x27;è¾“å‡ºå±‚/ç¬¬äºŒå±‚&#x27;&#x27;&#x27;</span></span><br><span class="line">                        [ np.random.normal(size=(outputS,hidWidth)), </span><br><span class="line">                          np.zeros(shape=(outputS,<span class="number">1</span>))],</span><br><span class="line">            ]</span><br><span class="line">        </span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;éšbatchSizeåŠ¨æ€å˜åŒ–ï¼Œæœ‰å¾…ä¼˜åŒ–&#x27;&#x27;&#x27;</span></span><br><span class="line">        self.cache = [  <span class="comment"># ç¼“å­˜listï¼Œæ¯ä¸ªå°listä»£è¡¨ä¸€ä¸ªå±‚çš„ä¸­é—´å˜é‡</span></span><br><span class="line">                        <span class="comment">#&#x27;&#x27;&#x27;è¾“å…¥å±‚&#x27;&#x27;&#x27;</span></span><br><span class="line">                        [np.zeros(shape=(inputS,preCacheSize)),    <span class="comment"># æ•°æ®çš„X</span></span><br><span class="line">                         np.zeros(shape=(outputS,preCacheSize))],  <span class="comment"># æ•°æ®çš„Y</span></span><br><span class="line">                        <span class="comment">#&#x27;&#x27;&#x27;ç¬¬ä¸€å±‚&#x27;&#x27;&#x27;</span></span><br><span class="line">                        [ np.zeros(shape=(hidWidth,preCacheSize)), <span class="comment"># çº¿æ€§è®¡ç®—ç»“æœ</span></span><br><span class="line">                         np.zeros(shape=(hidWidth,preCacheSize))], <span class="comment"># æ¿€æ´»ï¼ˆéçº¿æ€§ï¼‰ç»“æœ</span></span><br><span class="line">                        <span class="comment">#&#x27;&#x27;&#x27;è¾“å‡ºå±‚/ç¬¬äºŒå±‚&#x27;&#x27;&#x27;</span></span><br><span class="line">                        [ np.zeros(shape=(outputS,preCacheSize)),</span><br><span class="line">                         np.zeros(shape=(outputS,preCacheSize))]</span><br><span class="line">            ]</span><br><span class="line">        self.grad = copy.deepcopy(self.param)   <span class="comment"># æ¢¯åº¦ç¼“å­˜çš„å¤§å°å’Œå¯è®­ç»ƒå‚æ•°æ˜¯ä¸€æ ·å¤šçš„</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ç»Ÿä¸€æ¿€æ´»å‡½æ•°</span></span><br><span class="line">        self.activeFunc = active</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;åˆ›å»ºå…¨è¿æ¥ç½‘ç»œæˆåŠŸï¼Œç»“æ„ï¼š<span class="subst">&#123;inputS&#125;</span>-&gt;<span class="subst">&#123;hidWidth&#125;</span>-&gt;<span class="subst">&#123;outputS&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__ReLU</span>(<span class="params">self,layerID:<span class="built_in">int</span>,forward:<span class="built_in">bool</span>=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        æ¿€æ´»å‡½æ•°ï¼Œæ”¯æŒæ­£åå‘</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> forward:        </span><br><span class="line">            self.cache[layerID][<span class="number">1</span>] = np.maximum(<span class="number">0</span>,self.cache[layerID][<span class="number">0</span>]) <span class="comment"># ç»´åº¦ä¼šè‡ªåŠ¨æ‰©å¼ </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:   <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">            <span class="keyword">return</span> (self.cache[layerID][<span class="number">1</span>] &gt; <span class="number">0</span>).astype(dtype=np.int0)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__Sigmoid</span>(<span class="params">self,layerID:<span class="built_in">int</span>,forward:<span class="built_in">bool</span>=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        æ¿€æ´»å‡½æ•°ï¼Œæ”¯æŒæ­£åå‘</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> forward:</span><br><span class="line">            self.cache[layerID][<span class="number">1</span>] = <span class="number">1</span>/(<span class="number">1</span>+np.exp(np.subtract(<span class="number">0</span>,self.cache[layerID][<span class="number">0</span>])))</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.cache[layerID][<span class="number">1</span>]*(<span class="number">1</span>-self.cache[layerID][<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__softmax</span>(<span class="params">self,inputD:np.ndarray</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        æ¿€æ´»å‡½æ•°ï¼Œæ”¯æŒæ­£å‘</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        __DEBUG_SOFTMAX__ = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> __DEBUG_SOFTMAX__:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;inputD : <span class="subst">&#123;inputD.shape&#125;</span>&quot;</span>)</span><br><span class="line">        inputD = np.exp(inputD) <span class="comment"># ~ [m_2,N]</span></span><br><span class="line">        <span class="keyword">if</span> __DEBUG_SOFTMAX__:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;inputD.exp : <span class="subst">&#123;inputD.shape&#125;</span>&quot;</span>)</span><br><span class="line">        sumD = np.<span class="built_in">sum</span>(inputD,axis=<span class="number">0</span>,keepdims=<span class="literal">True</span>)  <span class="comment"># ~ [1,N]</span></span><br><span class="line">        <span class="keyword">if</span> __DEBUG_SOFTMAX__:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;sumD : <span class="subst">&#123;sumD.shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> inputD/sumD  <span class="comment"># ~ [m_2,N]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,inputX:np.ndarray,inputY:np.ndarray,Debuging:<span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        å‰å‘ä¼ æ’­æ–¹æ³•</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        inputX : np.ndarray</span></span><br><span class="line"><span class="string">            è¾“å…¥æ ·æœ¬æ•°æ®ï¼Œæ”¯æŒmini-Batch.ï¼ˆæ³¨æ„ç»´åº¦ä¸ºï¼š[dataSize,BatchSize]</span></span><br><span class="line"><span class="string">        inputY : np.ndarray</span></span><br><span class="line"><span class="string">            è¾“å…¥æ ‡ç­¾æ•°æ®ï¼Œæ”¯æŒmini-Batch.ï¼ˆæ³¨æ„ç»´åº¦ä¸ºï¼š[labelSize,BatchSize]</span></span><br><span class="line"><span class="string">        Debuging : bool, optional</span></span><br><span class="line"><span class="string">            è°ƒè¯•æ‰“å°ä½¿èƒ½ï¼Œä½¿ç”¨æ—¶ä¸å¼€å¯ï¼. The default is False.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        np.ndarray</span></span><br><span class="line"><span class="string">            ç½‘ç»œçš„è¾“å‡ºå±‚æ•°æ®.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.cache[<span class="number">0</span>][<span class="number">0</span>] = inputX   <span class="comment"># å­˜å‚¨æ•°æ®ï¼Œç”¨äºåç»­åå‘ä¼ æ’­ ~ [m_0,N]</span></span><br><span class="line">        self.cache[<span class="number">0</span>][<span class="number">1</span>] = inputY   <span class="comment"># ~ [classes,N]</span></span><br><span class="line">        <span class="keyword">if</span> Debuging:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;è¾“å…¥æ•°æ®å¤§å°ï¼š<span class="subst">&#123;self.cache[<span class="number">0</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œè¾“å…¥æ ‡ç­¾çš„å¤§å°ï¼š<span class="subst">&#123;self.cache[<span class="number">0</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ç¬¬ä¸€ä¸ªçº¿æ€§å±‚</span></span><br><span class="line">        self.cache[<span class="number">1</span>][<span class="number">0</span>] = self.param[<span class="number">1</span>][<span class="number">0</span>] @ self.cache[<span class="number">0</span>][<span class="number">0</span>] + self.param[<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># ~ [m_1,N] = [m_1,m_0] @ [m_0,N] + [m_1,1]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ¿€æ´»</span></span><br><span class="line">        <span class="keyword">if</span> self.activeFunc == <span class="string">&quot;relu&quot;</span>:</span><br><span class="line">            self.__ReLU(<span class="number">1</span>,forward=<span class="literal">True</span>) <span class="comment"># ~ [m_1,N]</span></span><br><span class="line">        <span class="keyword">elif</span> self.activeFunc == <span class="string">&quot;sigmoid&quot;</span>:</span><br><span class="line">            self.__Sigmoid(<span class="number">1</span>,forward=<span class="literal">True</span>)  <span class="comment"># ~ [m_1,N]</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;activate error!&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span>    </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è¾“å‡ºå±‚</span></span><br><span class="line">        self.cache[<span class="number">2</span>][<span class="number">0</span>] = self.param[<span class="number">2</span>][<span class="number">0</span>] @ self.cache[<span class="number">1</span>][<span class="number">1</span>] + self.param[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># ~ [m_2,N] = [m_2,m_1] @ [m_1,N] + [m_2,1]</span></span><br><span class="line">        <span class="comment"># æ¿€æ´»</span></span><br><span class="line">        self.cache[<span class="number">2</span>][<span class="number">1</span>] = self.__softmax(self.cache[<span class="number">2</span>][<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># ~ [m_2,N]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.cache[<span class="number">2</span>][<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        åå‘ä¼ æ’­</span></span><br><span class="line"><span class="string">        æ±‚å„ä¸ªå‚æ•°å±‚çš„æ¢¯åº¦</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="string">&#x27;--- å€’1å±‚ï¼ˆsoftmaxè¾“å‡ºå±‚ï¼‰ ---&#x27;</span></span><br><span class="line">        <span class="comment"># æŸå¤±å‡½æ•°å¯¹ softmaxæ¿€æ´»å‰&amp;æœ€åä¸€ä¸ªçº¿æ€§å±‚å çš„åå¯¼</span></span><br><span class="line">        dL_dz = (self.cache[<span class="number">2</span>][<span class="number">1</span>] - self.cache[<span class="number">0</span>][<span class="number">1</span>]) / (self.cache[<span class="number">0</span>][<span class="number">1</span>].shape[<span class="number">1</span>]) <span class="comment"># é¢„æµ‹å€¼å‘é‡å‡å»çœŸå®å€¼çš„one-hotå‘é‡</span></span><br><span class="line">        <span class="comment"># [m2,N] = ( [m2,N] - [m2,N] ) /N</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æŸå¤±å‡½æ•°å¯¹ç¬¬äºŒå±‚ï¼ˆæœ€åï¼‰å¯è®­ç»ƒå‚æ•°åå¯¼</span></span><br><span class="line">        self.grad[<span class="number">2</span>][<span class="number">0</span>] = dL_dz @ self.cache[<span class="number">1</span>][<span class="number">1</span>].T   <span class="comment"># æŸå¤±å¯¹wåå¯¼</span></span><br><span class="line">        <span class="comment"># ~ [m2,m1] = [m2,N] @ [m1,N]^T</span></span><br><span class="line">        self.grad[<span class="number">2</span>][<span class="number">1</span>] = np.<span class="built_in">sum</span>(dL_dz,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>) <span class="comment"># æŸå¤±å¯¹båå¯¼</span></span><br><span class="line">        <span class="comment"># ~ [m_2,1] = sum([m_2,N])</span></span><br><span class="line">        </span><br><span class="line">        <span class="string">&#x27;--- å€’2å±‚ ---&#x27;</span></span><br><span class="line">        <span class="comment"># æŸå¤±å‡½æ•°å¯¹ ç¬¬ä¸€ä¸ªéšè—å±‚çš„æ¿€æ´»è¾“å‡º çš„åå¯¼     </span></span><br><span class="line">        dL_dz = (dL_dz.T @ self.param[<span class="number">2</span>][<span class="number">0</span>]).T </span><br><span class="line">        <span class="comment"># ~ [m1,N] = ([m_2,N]^T @ [m_2,m_1])^T</span></span><br><span class="line">        <span class="comment"># æŸå¤±å‡½æ•°å¯¹ ç¬¬ä¸€ä¸ªéšè—å±‚çš„æ¿€æ´»å‰&amp;çº¿æ€§è¾“å‡º çš„åå¯¼</span></span><br><span class="line">        <span class="keyword">if</span> self.activeFunc == <span class="string">&quot;relu&quot;</span>:</span><br><span class="line">            dL_dz = dL_dz * self.__ReLU(<span class="number">1</span>,forward=<span class="literal">False</span>)  <span class="comment"># ~ [m_1,N] * [m_1,N]</span></span><br><span class="line">        <span class="keyword">elif</span> self.activeFunc == <span class="string">&quot;sigmoid&quot;</span>:</span><br><span class="line">            dL_dz = dL_dz * self.__Sigmoid(<span class="number">1</span>,forward=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;active error in backforward&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">        <span class="comment"># æŸå¤±å‡½æ•°å¯¹ç¬¬ä¸€å±‚å¯è®­ç»ƒå‚æ•°åå¯¼</span></span><br><span class="line">        self.grad[<span class="number">1</span>][<span class="number">0</span>] =dL_dz @ self.cache[<span class="number">0</span>][<span class="number">0</span>].T   <span class="comment"># æŸå¤±å¯¹wåå¯¼</span></span><br><span class="line">        self.grad[<span class="number">1</span>][<span class="number">1</span>] = np.<span class="built_in">sum</span>(dL_dz,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>) <span class="comment"># æŸå¤±å¯¹båå¯¼</span></span><br><span class="line">        </span><br><span class="line">        <span class="string">&#x27;--- ç»“æŸ ---&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">SGD</span>(<span class="params">self,lr:<span class="built_in">int</span> = <span class="number">0.001</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        éšæœºæ¢¯åº¦ä¸‹é™æ³•ï¼Œå›ºå®šå­¦ä¹ ç‡æ›´æ–°æƒé‡å’Œåç½®</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Parameters</span></span><br><span class="line"><span class="string">        ----------</span></span><br><span class="line"><span class="string">        lr : int, optional</span></span><br><span class="line"><span class="string">            å­¦ä¹ ç‡. The default is 0.001.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        None.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            <span class="keyword">for</span> typ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">                self.param[layer+<span class="number">1</span>][typ] -= lr * self.grad[layer+<span class="number">1</span>][typ]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        æ‰“å°ç½‘ç»œç»“æ„ä¿¡æ¯</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---å±‚ç»“æ„ï¼š&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬ä¸€å±‚ï¼šæƒé‡<span class="subst">&#123;self.param[<span class="number">1</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.param[<span class="number">1</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬äºŒå±‚ï¼šæƒé‡<span class="subst">&#123;self.param[<span class="number">2</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.param[<span class="number">2</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---æ¢¯åº¦ç»“æ„ï¼š&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬ä¸€å±‚ï¼šæƒé‡<span class="subst">&#123;self.grad[<span class="number">1</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.grad[<span class="number">1</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬äºŒå±‚ï¼šæƒé‡<span class="subst">&#123;self.grad[<span class="number">2</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.grad[<span class="number">2</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---ç¼“å­˜é‡ï¼š&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;è¾“å…¥å±‚ï¼š<span class="subst">&#123;self.cache[<span class="number">0</span>][<span class="number">0</span>].shape&#125;</span>å’Œ<span class="subst">&#123;self.cache[<span class="number">0</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬ä¸€å±‚ï¼šæƒé‡<span class="subst">&#123;self.cache[<span class="number">1</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.cache[<span class="number">1</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬äºŒå±‚ï¼šæƒé‡<span class="subst">&#123;self.cache[<span class="number">2</span>][<span class="number">0</span>].shape&#125;</span>ï¼Œåç½®<span class="subst">&#123;self.cache[<span class="number">2</span>][<span class="number">1</span>].shape&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<p>è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨æ„å»ºä¸€ä¸ª<code>FC()</code>ç½‘ç»œå¯¹è±¡åï¼Œé€šè¿‡è°ƒç”¨3ä¸ªæ–¹æ³•<code>FC.forward()</code>ã€<code>FC.backward()</code>å’Œ<code>FC.SGD()</code>å°±å¯ä»¥è¿›è¡Œç½‘ç»œçš„è®­ç»ƒäº†ã€‚</p>
<h3 id="ç½‘ç»œè®­ç»ƒ"><a href="#ç½‘ç»œè®­ç»ƒ" class="headerlink" title="ç½‘ç»œè®­ç»ƒ"></a>ç½‘ç»œè®­ç»ƒ</h3><p>è¿™ä¸€éƒ¨åˆ†è¾ƒä¸ºç®€å•ï¼Œå®ç°ä¸ºï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸»ç¨‹åº</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># å‚æ•°è®¾ç½®</span></span><br><span class="line">    EPOCH = <span class="number">100</span></span><br><span class="line">    BATCHSIZE = <span class="number">32</span></span><br><span class="line">    LEARNRATE = <span class="number">0.001</span></span><br><span class="line">    </span><br><span class="line">    HIDLAYERWIDTH = <span class="number">128</span></span><br><span class="line">    ACTIVATEFUNC = <span class="string">&quot;relu&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æ•°æ®è®°å½•</span></span><br><span class="line">    writer = tensorboard.SummaryWriter(<span class="string">&#x27;./log/MNIST-FC&#x27;</span>+<span class="built_in">str</span>(HIDLAYERWIDTH)+ACTIVATEFUNC)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æ•°æ®é›†åŠ è½½</span></span><br><span class="line">    transformer = torchvision.transforms.Compose([</span><br><span class="line">                        torchvision.transforms.ToTensor(),</span><br><span class="line">                        torchvision.transforms.Normalize(</span><br><span class="line">                            (<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,) )</span><br><span class="line">                         ])</span><br><span class="line">    </span><br><span class="line">    trainDataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./Data&quot;</span>,    </span><br><span class="line">                                           train = <span class="literal">True</span>,</span><br><span class="line">                                           download= <span class="literal">True</span>,</span><br><span class="line">                                           transform= transformer</span><br><span class="line">                                           )</span><br><span class="line">    trainLoader = torch.utils.data.DataLoader(trainDataset,</span><br><span class="line">                                              batch_size= BATCHSIZE,    <span class="comment"># Batch Sizeï¼</span></span><br><span class="line">                                              shuffle= <span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    testDataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./Data&quot;</span>,</span><br><span class="line">                                           train = <span class="literal">False</span>,</span><br><span class="line">                                           download= <span class="literal">True</span>,</span><br><span class="line">                                           transform= transformer)</span><br><span class="line">    </span><br><span class="line">    testLoader = torch.utils.data.DataLoader(testDataset,</span><br><span class="line">                                              batch_size= BATCHSIZE,    <span class="comment"># Batch Sizeï¼</span></span><br><span class="line">                                              shuffle= <span class="literal">True</span>,</span><br><span class="line">                                              num_workers=<span class="number">2</span>)</span><br><span class="line">    testIter = <span class="built_in">iter</span>(testLoader)</span><br><span class="line">    </span><br><span class="line">    trainD = trainDataset.data.numpy()</span><br><span class="line">    trainD = trainD.reshape(trainD.shape[<span class="number">0</span>],-<span class="number">1</span>).T</span><br><span class="line">    trainD = trainD / <span class="number">256</span></span><br><span class="line">    trainT = trainDataset.targets.numpy().T</span><br><span class="line">    </span><br><span class="line">    testD = testDataset.data.numpy()</span><br><span class="line">    testD = testD.reshape(testD.shape[<span class="number">0</span>],-<span class="number">1</span>).T</span><br><span class="line">    testD = testD / <span class="number">256</span></span><br><span class="line">    testT = testDataset.targets.numpy().T</span><br><span class="line">    </span><br><span class="line">    samp = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainLoader))</span><br><span class="line">    samp[<span class="number">0</span>] = samp[<span class="number">0</span>].numpy(); samp[<span class="number">1</span>] = samp[<span class="number">1</span>].numpy()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">        plt.figure(i)</span><br><span class="line">        plt.imshow(samp[<span class="number">0</span>][i][<span class="number">0</span>])</span><br><span class="line">        plt.title(<span class="built_in">str</span>(samp[<span class="number">1</span>][i]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># åˆ›å»ºæ¨¡å‹</span></span><br><span class="line">    model = FC(inputS=<span class="number">28</span>*<span class="number">28</span>,</span><br><span class="line">               hidWidth=HIDLAYERWIDTH,</span><br><span class="line">               outputS=<span class="number">10</span>,</span><br><span class="line">               active=ACTIVATEFUNC)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># è®­ç»ƒæ¨¡å‹</span></span><br><span class="line">    Log_id = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,EPOCH+<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># ä¸€æ¬¡è®­ç»ƒ</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;-------- <span class="subst">&#123;ep&#125;</span>&#x27;th epoch begin --------&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> idx,(sampX,sampY) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainLoader):</span><br><span class="line">            <span class="comment"># æ•°æ®ç»´åº¦é¢„å¤„ç†</span></span><br><span class="line">            sampX = sampX.numpy()</span><br><span class="line">            sampX = sampX.reshape(sampX.shape[<span class="number">0</span>],-<span class="number">1</span>).T</span><br><span class="line">            sampX = sampX / <span class="number">256</span></span><br><span class="line">            </span><br><span class="line">            sampY_vector = torch.nn.functional.one_hot(sampY,num_classes = <span class="number">10</span>).numpy().T</span><br><span class="line">            <span class="comment"># å‰å‘ä¼ æ’­</span></span><br><span class="line">            pred =  model.forward(sampX, sampY_vector)</span><br><span class="line">            <span class="comment"># åå‘ä¼ æ’­</span></span><br><span class="line">            model.backward()</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">            <span class="comment"># SGD</span></span><br><span class="line">            model.SGD(lr = LEARNRATE)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># æ•°æ®æ‰“å°</span></span><br><span class="line">            <span class="keyword">if</span> idx %<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># æŸå¤±è®¡ç®—</span></span><br><span class="line">                loss = Loss_CrossEntropy(pred,sampY_vector)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;ç¬¬<span class="subst">&#123;ep&#125;</span>çš„<span class="subst">&#123;idx&#125;</span>æ¬¡Batchäº¤å‰ç†µæŸå¤±:<span class="subst">&#123;loss&#125;</span>&quot;</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># å‡†ç¡®åº¦è®¡ç®—</span></span><br><span class="line">                testX,testY = testIter.<span class="built_in">next</span>()</span><br><span class="line">                testX = testX.numpy()</span><br><span class="line">                testX = testX.reshape(testX.shape[<span class="number">0</span>],-<span class="number">1</span>).T</span><br><span class="line">                testX = testX / <span class="number">256</span></span><br><span class="line">                <span class="keyword">if</span> Log_id % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                    testIter = <span class="built_in">iter</span>(testLoader)</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line">                acc_train = model_accuracyTest(model, sampX, sampY.numpy())</span><br><span class="line">                acc_test = model_accuracyTest(model, testX, testY.numpy())</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;è®­ç»ƒé›†å‡†ç¡®åº¦:<span class="subst">&#123;acc_train*<span class="number">100</span>&#125;</span>%,æµ‹è¯•é›†å‡†ç¡®åº¦:<span class="subst">&#123;acc_test*<span class="number">100</span>&#125;</span>%&quot;</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># è®°å½•æ•°æ®</span></span><br><span class="line">                writer.add_scalar(<span class="string">&quot;æµ‹è¯•é›†å‡†ç¡®åº¦&quot;</span>, acc_test,Log_id)</span><br><span class="line">                writer.add_scalar(<span class="string">&quot;è®­ç»ƒé›†å‡†ç¡®åº¦&quot;</span>, acc_train,Log_id)</span><br><span class="line">                writer.add_scalar(<span class="string">&quot;äº¤å‰ç†µæŸå¤±&quot;</span>, loss,Log_id)</span><br><span class="line">                Log_id +=<span class="number">1</span></span><br><span class="line">        </span><br></pre></td></tr></table></figure>

<p>è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®¾è®¡äº†ä¸¤ä¸ªç”¨æ¥è¯„ä¼°ç½‘ç»œçš„æ€§èƒ½ï¼Œåˆ†åˆ«æ˜¯æ±‚æŸå¤±å‡½æ•°å’Œé¢„æµ‹å‡†ç¡®åº¦ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Loss_CrossEntropy</span>(<span class="params">pred:np.ndarray, real:np.ndarray</span>):</span><br><span class="line">    <span class="comment"># pred ~ [classes,N] , real ~ [classes,N]</span></span><br><span class="line">    </span><br><span class="line">    entropy = real * np.log(pred +<span class="number">1e-10</span>)    <span class="comment"># 1e-10é˜²æ­¢æ— ç©·äº§ç”Ÿ</span></span><br><span class="line">    </span><br><span class="line">    entropy = -np.<span class="built_in">sum</span>(entropy) / real.shape[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> entropy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">model_accuracyTest</span>(<span class="params">model:FC, inputD:np.ndarray, target:np.ndarray</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    </span><br><span class="line">    res = model.forward(inputD, target) <span class="comment"># æ¨¡å‹æ¨å¯¼</span></span><br><span class="line">    </span><br><span class="line">    res = np.argmax(res,axis=<span class="number">0</span>) <span class="comment"># é€‰å‡ºæ¦‚ç‡æœ€å¤§çš„ç±»å‹</span></span><br><span class="line">    </span><br><span class="line">    acc = np.mean(np.equal(res,target))</span><br></pre></td></tr></table></figure>

<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ•°æ®çš„åŠ è½½å’Œæ¨¡å‹æ•ˆæœè®°å½•å¯è§†åŒ–éƒ½æ˜¯å€ŸåŠ©çš„<code>PyTorch</code>ï¼Œæ‰€ä»¥åœ¨æ–‡ä»¶æœ€å¼€å¤´å¯¼å…¥çš„ï¼ˆæ‰€æœ‰è¾…åŠ©çš„ï¼‰åº“æœ‰ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch,torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.utils.tensorboard <span class="keyword">as</span> tensorboard</span><br></pre></td></tr></table></figure>

<p>ç„¶åæŠŠç½‘ç»œè®­ç»ƒèµ·æ¥å§ï¼ç¬”è€…ä½¿ç”¨çš„ç¯å¢ƒä¸ºï¼š</p>
<ul>
<li>Anaconda 4.10.3</li>
<li>Python 3.9.7</li>
<li>Spyder 5.1.2</li>
<li>PyTorch 1.9.0</li>
<li>Numpy 1.21.2</li>
<li>CPUï¼ši5-7300HQï¼ˆç¬”è®°æœ¬å“¦ï¼‰</li>
</ul>
<p><img src="http://imgjry.fangyikuan.xyz/20211019/20211019-NNC-2.png" alt="è¿è¡Œç¨‹åº"></p>
<p>é‚£ä¹ˆæ¥ä¸‹æ¥ï¼Œçœ‹ä¸€ä¸‹ç½‘ç»œçš„è¿è¡Œæ•ˆæœå¦‚ä½•å§ï¼ä»£ç ä¸­ä½¿ç”¨äº†<code>TensorBoard</code>æ¥è®°å½•æ•°æ®ï¼Œæ‰€ä»¥åœ¨è®­ç»ƒç»“æŸåï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿è¡Œç›®å½•ä¸‹è¿è¡Œå‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tensorboard --logdir=./log</span><br></pre></td></tr></table></figure>

<p><img src="http://imgjry.fangyikuan.xyz/20211019/20211019-NNC-3.png" alt="ç»“æœ"></p>
<p>100æ¬¡epochåçš„è®­ç»ƒæ•ˆæœä¸ºï¼š</p>
<ul>
<li>è®­ç»ƒé›†å‡†ç¡®åº¦ï¼š85.36%</li>
<li>æµ‹è¯•é›†å‡†ç¡®åº¦ï¼š78.25%</li>
<li>äº¤å‰ç†µæŸå¤±ï¼š0.8257</li>
</ul>
<h2 id="çŸ¥è¯†æ€»ç»“"><a href="#çŸ¥è¯†æ€»ç»“" class="headerlink" title="çŸ¥è¯†æ€»ç»“"></a>çŸ¥è¯†æ€»ç»“</h2><p>æ‰€ä»¥ï¼Œæˆ‘ä»¬æ€»ç»“ä¸€ä¸‹åœ¨ç¬¬<code>L</code>å±‚å…¨è¿æ¥ç½‘ç»œçš„å‚æ•°é‡æ˜¯ï¼š</p>
<p>$$<br>m_{L}*m_{L-1} + m_{L}<br>$$</p>
<p>ç¬¬<code>L</code>å±‚çš„æ¢¯åº¦ä¿¡æ¯å¤§å°å’Œè¯¥å±‚çš„ï¼ˆå¯è®­ç»ƒï¼‰å‚æ•°é‡æ˜¯ä¸€æ ·çš„ï¼š</p>
<p>$$<br>m_{L}*m_{L-1} + m_{L}<br>$$</p>
<p>åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œç¬¬<code>L</code>å±‚éœ€è¦ç¼“å­˜çš„æ•°æ®é‡ä¸ºï¼š</p>
<p>$$<br>m _ {L} * BatchSize * 2<br>$$</p>
<p>ä¸ºäº†æœ€å°åŒ–å­˜å‚¨ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ç½‘ç»œåå‘ä¼ æ’­æ—¶ï¼Œè®©åå¯¼è®¡ç®—æ¯æ›´æ–°å®Œä¸€å±‚çš„æ¢¯åº¦ä¿¡æ¯å°±å»æ‰ä¸å†ä¿ç•™ï¼Œæ‰€ä»¥åå‘ä¼ æ’­æ—¶ï¼Œéœ€è¦ä¸ºå†…å­˜å¤§å°åŠ¨æ€å˜åŒ–çš„åå¯¼æ•°æ®é¢„ç•™ç©ºé—´ä¸ºï¼š</p>
<p>$$<br>m _ {max} * BatchSize<br>$$</p>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬è®¡ç®—å‡ºæ¥çš„ç©ºé—´ï¼Œä¸ä¸€å®šå°±æ˜¯è®¾å¤‡éœ€è¦çš„å®é™…ç©ºé—´ã€‚æ¯”å¦‚ï¼Œåœ¨è¿›è¡ŒçŸ©é˜µè¿ç®—çš„æ—¶å€™ï¼Œä¸­é—´å˜é‡è¿˜æ˜¯è¦å ç”¨ä¸€å®šçš„ç©ºé—´ï¼Œè¿™æ˜¯ç§‘å­¦è¿ç®—åº“çš„å†…å­˜é—®é¢˜ï¼›ä»¥åŠPythonå¯¹å†…å­˜çš„å æœ‰å¯æ¯”C++å¤§å¤šäº†ï¼Œè¿™æ˜¯ç¼–ç¨‹è¯­è¨€çš„å†…å­˜é—®é¢˜ï¼›ç­‰ç­‰ã€‚æ‰€ä»¥ï¼Œæœ€åè¿˜æ˜¯è¦æœ‰ä¸€å®šçš„ç»éªŒå’Œå¯¹å¼€å‘ç¯å¢ƒåº•å±‚çš„äº†è§£</p>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          Donate
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyrightï¼š </strong>
          
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        åˆ†äº«
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>æ‰«ä¸€æ‰«ï¼Œåˆ†äº«åˆ°å¾®ä¿¡</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://www.singularity-blog.top/2021/10/19/NeuralNetwork-UnderlyingCalculate/" alt="å¾®ä¿¡åˆ†äº«äºŒç»´ç ">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NeuralNetwork/" rel="tag">NeuralNetwork</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Numpy/" rel="tag">Numpy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C/" rel="tag">å…¨è¿æ¥ç½‘ç»œ</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2021/12/24/MVT-Digitizer-byFPGA/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸Šä¸€ç¯‡</strong>
        <div class="article-nav-title">
          
            FPGAå®ç°è„‰å†²ä¿¡å·MVTé‡åŒ–å™¨
          
        </div>
      </a>
    
    
      <a href="/2021/09/17/NeuralNetWork-Optimizer/" class="article-nav-link">
        <strong class="article-nav-caption">ä¸‹ä¸€ç¯‡</strong>
        <div class="article-nav-title">ç¥ç»ç½‘ç»œè®­ç»ƒä¼˜åŒ–å™¨åŠå·¥å…·</div>
      </a>
    
  </nav>

  
   
    
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2022-2024
        <i class="ri-heart-fill heart_icon"></i> RY.J
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzzç»Ÿè®¡ -->
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/S-logo-side.svg" alt="Singularity-blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">ä¸»é¡µ</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">å½’æ¡£</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">åˆ†ç±»</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">æ ‡ç­¾</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/aboutMe">å…³äºæˆ‘</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>è¯·æˆ‘å–æ¯å’–å•¡å§~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">æ”¯ä»˜å®</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">å¾®ä¿¡</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // sliderå±•å¼€çŠ¶æ€
                // todo: è¿™æ ·ä¸å¥½ï¼Œåé¢æ”¹æˆçŠ¶æ€
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // è·å¾—åŸå›¾å°ºå¯¸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->
 
    
 
<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // ç­‰å¾…ä¸¤ç§’é’Ÿåæ¢å¤
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // ç­‰å¾…ä¸¤ç§’é’Ÿåæ¢å¤
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="86"
        src="//music.163.com/outchain/player?type=2&id=1357887419&auto=0&height=66"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>